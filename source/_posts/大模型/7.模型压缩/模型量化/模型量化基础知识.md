---
title: 大模型量化概述
date: 2025-01-08 17:40:38
tags: 大模型量化基础知识
categories: 大模型量化
---
## 模型量化简介
## 定义
模型量化是指以较低的推理精度损失将连续取值(通常为float32或者大量可能的离散值)的浮点型权重近似为有限多个离散值(通常为int8)的过程。
## 量化分类
根据应用量化压缩模型的阶段，可以将模型量化分为:
1. 量化感知训练(Quantization Aware Training,QAT)

在模型训练过程中加入伪量化算子通过训练时统计输入输出的数据范围可以提升量化后模型的精度，适用于对模型精度要求较高的场景;其量化目标无缝地集成到模型的训练过程中。这种方法使LLM在训练过程中适应低精度表示，增强其处理由量化引起的精度损失的能力。这种适应旨在量化过程之后保持更高性能。

2. 量化感知微调(Quantization-Aware Fine-tuning,QAF)

在微调过程中对LLM进行量化主要目标是确保经过微调的LLM在量化为较低位宽后仍保持性能，通过将量化感知整合到微调中，以在模型压缩和保持性能之间取得平衡。

3. 训练后量化(Post Training Quantization,PTQ)

在LLM训练完成后对其参数进行量化，只需要少量校准数据，适用于追求高易用性和缺乏训练资源的场景。主要目标是减少LLM的存储和计算复杂性，而无需对LLM架构进行修改或进行重新训练。PTQ的主要优势在于其简单性和高效性。但PTQ可能会在量化过程中引入一定程度的精度损失。
## 线性量化分类
对称量化中，量化前后的 0 点是对齐的，因此不需要记录零点，将参数量化到$(-127,127)$。它适合对分布良好且均值为 0 的参数进行量化。因此对称量化常用于对 weight 量化。

非对称量化（如右图所示）中，量化前后 0 点不对齐，需要额外记录一个 offset，也就是零点，将参数量化到$(0,255)$。非对称量化常用于对 activation 做量化。